/**
 * Servicio de IA Inteligente para LM Studio
 * AnÃ¡lisis de mensajes, detecciÃ³n de intenciÃ³n de compra y generaciÃ³n de respuestas empÃ¡ticas
 */

import axios from 'axios';
import { log } from '../core/logger.js';
import { contextManager } from './ContextManager.js';

export class IntelligentAIService {
  constructor() {
    this.lmStudioEndpoint =
      process.env.AI_ENDPOINT || 'http://localhost:1234/v1/chat/completions';
    this.model = process.env.AI_MODEL || 'local-model';
    this.maxTokens = 500;
    this.temperature = 0.7;

    // Palabras clave para detecciÃ³n de intenciÃ³n de compra
    this.purchaseKeywords = [
      'quiero participar',
      'cÃ³mo se paga',
      'me interesa',
      'mÃ¡ndame la info',
      'quiero comprar',
      'cÃ³mo funciona',
      'cuÃ¡nto cuesta',
      'precio',
      'inscribir',
      'apuntar',
      'participar',
      'informaciÃ³n',
      'detalles',
    ];

    // Palabras de rechazo
    this.rejectionKeywords = [
      'no me interesa',
      'no quiero',
      'no gracias',
      'dÃ©jame en paz',
      'no molestes',
      'estafa',
      'fraude',
      'no confÃ­o',
      'stop',
      'basta',
    ];
  }

  /**
   * Analiza un mensaje y determina la respuesta apropiada
   */
  async analizarMensaje(phone, mensaje, contexto = null) {
    try {
      // Cargar contexto si no se proporciona
      if (!contexto) {
        contexto = await contextManager.cargarContexto(phone);
      }

      // Detectar intenciÃ³n de compra
      const intencionCompra = this.detectarIntencionCompra(mensaje, contexto);

      // Detectar rechazo
      const esRechazo = this.detectarRechazo(mensaje);

      // Generar respuesta empÃ¡tica basada en contexto
      const respuesta = await this.generarRespuestaEmpatica(
        mensaje,
        contexto,
        intencionCompra,
        esRechazo
      );

      return {
        intencionCompra,
        esRechazo,
        respuesta,
        contextoActualizado: contexto,
      };
    } catch (error) {
      log(`âŒ Error analizando mensaje para ${phone}: ${error.message}`);
      return {
        intencionCompra: { detectada: false, confianza: 0 },
        esRechazo: false,
        respuesta:
          'Disculpa, hubo un error procesando tu mensaje. Â¿PodrÃ­as repetirlo?',
        contextoActualizado: contexto,
      };
    }
  }

  /**
   * Detecta intenciÃ³n de compra en el mensaje
   */
  detectarIntencionCompra(mensaje, contexto) {
    const textoLower = mensaje.toLowerCase();
    let confianza = 0;
    const palabrasEncontradas = [];

    // Buscar palabras clave directas
    this.purchaseKeywords.forEach(keyword => {
      if (textoLower.includes(keyword)) {
        confianza += 0.3;
        palabrasEncontradas.push(keyword);
      }
    });

    // Analizar contexto para ajustar confianza
    if (contexto.nivelEngagement > 60) {
      confianza += 0.2;
    }

    if (contexto.preguntas.length > 2) {
      confianza += 0.1;
    }

    if (contexto.intereses.length > 0) {
      confianza += 0.1;
    }

    // Palabras de urgencia
    const urgencyWords = ['urgente', 'rÃ¡pido', 'ya', 'ahora', 'inmediato'];
    if (urgencyWords.some(word => textoLower.includes(word))) {
      confianza += 0.15;
    }

    // Preguntas sobre proceso
    const processQuestions = ['cÃ³mo', 'cuÃ¡ndo', 'dÃ³nde', 'quÃ© necesito'];
    if (processQuestions.some(word => textoLower.includes(word))) {
      confianza += 0.1;
    }

    return {
      detectada: confianza >= 0.6,
      confianza: Math.min(confianza, 1.0),
      palabrasClave: palabrasEncontradas,
      timestamp: Date.now(),
    };
  }

  /**
   * Detecta si el mensaje es un rechazo
   */
  detectarRechazo(mensaje) {
    const textoLower = mensaje.toLowerCase();
    return this.rejectionKeywords.some(keyword => textoLower.includes(keyword));
  }

  /**
   * Genera una respuesta empÃ¡tica usando LM Studio
   */
  async generarRespuestaEmpatica(
    mensaje,
    contexto,
    intencionCompra,
    esRechazo
  ) {
    try {
      const prompt = this.construirPrompt(
        mensaje,
        contexto,
        intencionCompra,
        esRechazo
      );

      const response = await axios.post(
        this.lmStudioEndpoint,
        {
          model: this.model,
          messages: [
            {
              role: 'system',
              content: this.getSystemPrompt(),
            },
            {
              role: 'user',
              content: prompt,
            },
          ],
          max_tokens: this.maxTokens,
          temperature: this.temperature,
          stream: false,
        },
        {
          timeout: 30000,
          headers: {
            'Content-Type': 'application/json',
          },
        }
      );

      if (response.data && response.data.choices && response.data.choices[0]) {
        const respuestaIA = response.data.choices[0].message.content.trim();
        log(`ðŸ¤– Respuesta generada por IA para contexto: ${contexto.estado}`);
        return respuestaIA;
      }

      // Fallback si la IA no responde
      return this.generarRespuestaFallback(
        contexto,
        intencionCompra,
        esRechazo
      );
    } catch (error) {
      log(`âŒ Error conectando con LM Studio: ${error.message}`);
      return this.generarRespuestaFallback(
        contexto,
        intencionCompra,
        esRechazo
      );
    }
  }

  /**
   * Construye el prompt para la IA basado en el contexto
   */
  construirPrompt(mensaje, contexto, intencionCompra, esRechazo) {
    let prompt = `Mensaje del cliente: "${mensaje}"\n\n`;

    prompt += 'Contexto del cliente:\n';
    prompt += `- Estado actual: ${contexto.estado}\n`;
    prompt += `- Nivel de engagement: ${contexto.nivelEngagement}/100\n`;
    prompt += `- NÃºmero de mensajes: ${contexto.mensajes.length}\n`;
    prompt += `- Intereses detectados: ${contexto.intereses.join(', ') || 'ninguno'}\n`;
    prompt += `- Template enviado: ${contexto.templateEnviado ? 'SÃ­' : 'No'}\n`;

    if (contexto.mensajes.length > 0) {
      prompt += '\nÃšltimos mensajes:\n';
      contexto.mensajes.slice(-3).forEach((msg, index) => {
        prompt += `${index + 1}. "${msg.texto}"\n`;
      });
    }

    prompt += '\nAnÃ¡lisis:\n';
    prompt += `- IntenciÃ³n de compra detectada: ${intencionCompra.detectada ? 'SÃ­' : 'No'} (${Math.round(intencionCompra.confianza * 100)}%)\n`;
    prompt += `- Es rechazo: ${esRechazo ? 'SÃ­' : 'No'}\n`;

    prompt += '\nGenera una respuesta empÃ¡tica y persuasiva que:';

    if (esRechazo) {
      prompt +=
        '\n- Respete la decisiÃ³n del cliente pero deje la puerta abierta';
      prompt += '\n- Sea cordial y no insistente';
    } else if (intencionCompra.detectada) {
      prompt += '\n- Confirme el interÃ©s del cliente';
      prompt += '\n- Prepare para el envÃ­o del formulario';
      prompt += '\n- Genere expectativa sobre el proceso';
    } else {
      prompt += '\n- Responda a la consulta especÃ­fica';
      prompt += '\n- Mantenga el interÃ©s sin ser agresivo';
      prompt += '\n- Proporcione informaciÃ³n valiosa';
      prompt += '\n- Invite sutilmente a conocer mÃ¡s';
    }

    return prompt;
  }

  /**
   * Prompt del sistema para la IA
   */
  getSystemPrompt() {
    return `Eres un asesor comercial experto y empÃ¡tico especializado en sorteos y premios. Tu trabajo es:

1. PERSONALIDAD:
- Ser cÃ¡lido, empÃ¡tico y profesional
- Usar emojis apropiados pero sin exceso
- Adaptar el tono al nivel de engagement del cliente
- Ser persuasivo sin ser agresivo

2. CONOCIMIENTO DEL PRODUCTO:
- Sorteo de nÃºmeros de 4 dÃ­gitos
- Precio: $1.000 COP por nÃºmero
- Premio total: $4.000.000 COP
- Proceso simple y confiable

3. ESTRATEGIA DE COMUNICACIÃ“N:
- Responder directamente a las preguntas
- Crear urgencia sutil cuando sea apropiado
- Usar prueba social y testimonios
- Manejar objeciones con empatÃ­a
- Guiar hacia la acciÃ³n sin presionar

4. RESTRICCIONES:
- MÃ¡ximo 2-3 oraciones por respuesta
- Usar lenguaje natural y conversacional
- No hacer promesas exageradas
- Mantener la credibilidad siempre

Responde SOLO con el mensaje que enviarÃ­as al cliente, sin explicaciones adicionales.`;
  }

  /**
   * Genera respuesta de fallback cuando la IA no estÃ¡ disponible
   */
  generarRespuestaFallback(contexto, intencionCompra, esRechazo) {
    if (esRechazo) {
      return 'Entiendo perfectamente ðŸ˜Š No hay problema. Si en algÃºn momento cambias de opiniÃ³n, estarÃ© aquÃ­ para ayudarte. Â¡Que tengas un excelente dÃ­a! ðŸŒŸ';
    }

    if (intencionCompra.detectada) {
      return 'Â¡Perfecto! Me alegra saber que te interesa ðŸŽ‰ Te voy a enviar toda la informaciÃ³n para que puedas participar. Es muy fÃ¡cil y rÃ¡pido ðŸ˜Š';
    }

    // Respuestas segÃºn el estado del contexto
    switch (contexto.estado) {
      case 'nuevo':
        return 'Â¡Hola! ðŸ‘‹ Te cuento que tenemos un sorteo increÃ­ble con premio de $4.000.000 ðŸ’° Â¿Te gustarÃ­a conocer los detalles?';

      case 'interesado':
        return 'Genial que sigas interesado/a ðŸ˜Š Â¿Hay algo especÃ­fico que te gustarÃ­a saber sobre el sorteo?';

      default:
        return 'Gracias por tu mensaje ðŸ˜Š Â¿En quÃ© puedo ayudarte hoy con el sorteo?';
    }
  }

  /**
   * Verifica si LM Studio estÃ¡ disponible
   */
  async verificarConexionIA() {
    try {
      const response = await axios.get(
        this.lmStudioEndpoint.replace('/chat/completions', '/models'),
        {
          timeout: 5000,
        }
      );

      log('âœ… ConexiÃ³n con LM Studio establecida');
      return true;
    } catch (error) {
      log(`âŒ LM Studio no disponible: ${error.message}`);
      return false;
    }
  }

  /**
   * Analiza el sentimiento del mensaje
   */
  analizarSentimiento(mensaje) {
    const textoLower = mensaje.toLowerCase();

    const palabrasPositivas = [
      'genial',
      'perfecto',
      'excelente',
      'bueno',
      'sÃ­',
      'si',
      'ok',
      'vale',
    ];
    const palabrasNegativas = [
      'malo',
      'terrible',
      'no',
      'nunca',
      'jamÃ¡s',
      'imposible',
    ];

    let scorePositivo = 0;
    let scoreNegativo = 0;

    palabrasPositivas.forEach(palabra => {
      if (textoLower.includes(palabra)) scorePositivo++;
    });

    palabrasNegativas.forEach(palabra => {
      if (textoLower.includes(palabra)) scoreNegativo++;
    });

    if (scorePositivo > scoreNegativo) return 'positivo';
    if (scoreNegativo > scorePositivo) return 'negativo';
    return 'neutral';
  }
}

// Instancia singleton
export const intelligentAI = new IntelligentAIService();
